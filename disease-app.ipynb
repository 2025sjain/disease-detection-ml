{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "!pip -q install pyngrok\n",
    "!pip -q install streamlit\n",
    "!pip -q install patool\n",
    "\n",
    "import cv2\n",
    "import gdown\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import patoolib\n",
    "\n",
    "from joblib import dump\n",
    "from pyngrok import ngrok\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip PoisonIvy.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'RashData/Train/Train_2_Cases'\n",
    "val_dir = 'RashData/Validation/Validation_2_Cases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpi = 'PoisonIvy/train'\n",
    "testpi = 'PoisonIvy/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lyme Disease:\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    seed=42,\n",
    "    subset='training',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32)\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    seed=42,\n",
    "    subset='validation',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32)\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poison Ivy:\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    trainpi,\n",
    "    validation_split=0.2,\n",
    "    seed=42,\n",
    "    subset='training',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32)\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    testpi,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_datset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpi = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "modelpi.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=[\n",
    "             'accuracy',\n",
    "             tf.keras.metrics.AUC(name = 'auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "epochs = 6\n",
    "\n",
    "historypi = modelpi.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='sigmoid')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, 3, padding='same', activation='sigmoid')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, 3, padding='same', activation='sigmoid')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='sigmoid')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ld = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_ld.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=[\n",
    "             'accuracy',\n",
    "             tf.keras.metrics.AUC(name = 'auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "epochs = 8\n",
    "\n",
    "history_ld = model_ld.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/content'\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "max_samples = 3000\n",
    "\n",
    "blood_slide_url = 'https://drive.google.com/uc?id=1lffxAG8gykh1dh1pCP34uRkH3XMwuNt-'\n",
    "blood_slide_path = os.path.join(DATA_ROOT, 'blood_slide.jpg')\n",
    "gdown.download(blood_slide_url, blood_slide_path, True)\n",
    "\n",
    "!wget \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/Deep%20Dives/malaria_images.zip\"\n",
    "!unzip \"malaria_images.zip\"\n",
    "malaria_imgs_path = os.path.join(DATA_ROOT, 'malaria_images.zip')\n",
    "\n",
    "u_malaria_img_paths = glob.glob('/content/malaria_images/Uninfected/*png')\n",
    "p_malaria_img_paths = glob.glob('/content/malaria_images/Parasitized/*png')\n",
    "\n",
    "NUM_SAMPLES = len(u_malaria_img_paths) + len(p_malaria_img_paths)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "X_g = []\n",
    "\n",
    "for i in tqdm(range(max_samples)):\n",
    "  img = cv2.imread(u_malaria_img_paths[i])\n",
    "  X.append(cv2.resize(img,(50,50)))\n",
    "\n",
    "  gray_img = cv2.imread(u_malaria_img_paths[i],0)\n",
    "  X_g.append(cv2.resize(gray_img,(50,50)))\n",
    "\n",
    "  y.append(0)\n",
    "\n",
    "for i in tqdm(range(max_samples)):\n",
    "  img = cv2.imread(p_malaria_img_paths[i])\n",
    "  X.append(cv2.resize(img,(50,50)))\n",
    "\n",
    "  gray_img = cv2.imread(p_malaria_img_paths[i],0)\n",
    "  X_g.append(cv2.resize(gray_img,(50,50)))\n",
    "\n",
    "  y.append(1)\n",
    "\n",
    "X = np.stack(X)\n",
    "X_g = np.stack(X_g)\n",
    "X_reshaped = np.reshape(X_g,(X_g.shape[0],2500))\n",
    "\n",
    "y = np.array(y)\n",
    "\n",
    "blood_samples_dir = 'blood_samples'\n",
    "if (os.path.exists(blood_samples_dir) == False):\n",
    "  os.mkdir(blood_samples_dir)\n",
    "\n",
    "for i, img in enumerate(X[2995:3005]):\n",
    "  plt.imsave('test_img_{}.jpg'.format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size = 0.33, random_state = 42)\n",
    "model = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "model = model.fit(X_train, y_train)\n",
    "dump(model, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(modelpi, \"model.joblib2\")\n",
    "dump(model_ld, \"model.joblib3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit-multipage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "import base64\n",
    "from streamlit_multipage import MultiPage\n",
    "\n",
    "def info_page(st, **state):\n",
    "  st.title(\"Additional Information - Slideshow\")\n",
    "  st.write(\"\")\n",
    "  st.write(\"\")\n",
    "  with open(\"Remote Disease Detector.pdf\",\"rb\") as f:\n",
    "    base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "  pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"700\" height=\"1000\" type=\"application/pdf\"></iframe>'\n",
    "  st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "def image_page(st, **state):\n",
    "  st.title(\"Disease Image Classification\")\n",
    "  model = load(\"model.joblib\")\n",
    "  modelpi = load(\"model.joblib2\")\n",
    "  model_ld = load(\"model.joblib3\")\n",
    "\n",
    "  st.title('Lyme Disease Diagnosis')\n",
    "\n",
    "  uploaded_file = st.file_uploader(\"Upload Lyme Disease Rash File\")\n",
    "\n",
    "  if uploaded_file is not None:\n",
    "    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
    "    image = cv2.imdecode(file_bytes, 1)\n",
    "    small = cv2.resize(image, (32, 32))\n",
    "    small_batch = np.expand_dims(small, 0)\n",
    "    output = model_ld.predict(small_batch)\n",
    "    if output > 0.5257:\n",
    "      st.write(\"Negative: No Lyme Disease was detected.\")\n",
    "    else:\n",
    "      st.write(\"Positive: Lyme Disease was detected.\")\n",
    "      st.write(\"Please contact your local health care provider and follow the CDC guidlines for more information: https://www.cdc.gov/malaria/travelers/drugs.html\")\n",
    "\n",
    "  st.title('Malaria Diagnosis')\n",
    "  uploaded_file2 = st.file_uploader(\"Upload Malaria Blood Cell File\")\n",
    "\n",
    "  if uploaded_file2 is not None:\n",
    "    file_bytes = np.asarray(bytearray(uploaded_file2.read()), dtype=np.uint8)\n",
    "    image = cv2.imdecode(file_bytes, 1)\n",
    "\n",
    "    small = cv2.resize(image, (50, 50))\n",
    "    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray = np.reshape(gray, (1, 2500))\n",
    "    output = model.predict(gray)[0]\n",
    "    if output == 0:\n",
    "      st.write(\"Negative: No malaria was detected.\")\n",
    "    else:\n",
    "      st.write(\"Positive: Malaria was detected.\")\n",
    "      st.write(\"Please contact your local health care provider and follow the CDC guidlines for more information: https://www.cdc.gov/malaria/travelers/drugs.html\")\n",
    "\n",
    "  st.title('Poison Ivy Diagnosis')\n",
    "  uploaded_file3 = st.file_uploader(\"Upload Poison Ivy Rash File\")\n",
    "\n",
    "  if uploaded_file3 is not None:\n",
    "    file_bytes = np.asarray(bytearray(uploaded_file3.read()), dtype=np.uint8)\n",
    "    image = cv2.imdecode(file_bytes, 1)\n",
    "    small = cv2.resize(image, (32, 32))\n",
    "    small_batch = np.expand_dims(small, 0)\n",
    "\n",
    "    output = modelpi.predict(small_batch)\n",
    "    if output < 0.2:\n",
    "      st.write(\"Negative: No Poison Ivy was detected.\")\n",
    "    else:\n",
    "      st.write(\"Positive: Poison Ivy was detected.\")\n",
    "      st.write(\"Please contact your local health care provider and follow the CDC guidlines for more information: https://www.cdc.gov/malaria/travelers/drugs.html\")\n",
    "\n",
    "def home_page(st, **state):\n",
    "  st.title(\"Disease Detector Home Page\")\n",
    "  st.write(\"Our mission is to provide those without immediate access to healthcare professionals quick diagnosis for a plethora of diseases.\")\n",
    "  st.write(\"\")\n",
    "  image = Image.open('homepagepic.jpeg')\n",
    "  st.image(image, caption='**Through the use of machine learning algorithms such as Convolutional Neural Networks and Support Vector Machines, our project strives to diagnose diseases/illnesses for users.**')\n",
    "\n",
    "app = MultiPage()\n",
    "app.st = st\n",
    "app.navbar_name = \"Pages:\"\n",
    "app.navbar_style = \"SelectBox\"\n",
    "app.reset_button = \"-------------\"\n",
    "\n",
    "app.add_app(\"Disease Detector Home Page\", home_page)\n",
    "app.add_app(\"Image Classification\", image_page)\n",
    "app.add_app(\"Self-Diagnosis Test\", akinator_page)\n",
    "app.add_app(\"Additional Information\", info_page)\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngrok authtoken \"26IEGw1HiDLy0wj5uqrav4wIEaA_2mh3GVNpmJD7VMa2bRMWZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_url = ngrok.connect(port='80')\n",
    "print(public_url)\n",
    "!streamlit run --server.port 80 app.py >/dev/null"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
